{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os  # è™•ç†æª”æ¡ˆè·¯å¾‘\n",
        "import numpy as np  # è™•ç†æ•¸å€¼è³‡æ–™\n",
        "import pandas as pd  # è™•ç†è¡¨æ ¼å‹è³‡æ–™\n",
        "from tqdm import tqdm  # è®“è¿´åœˆåŠ ä¸Šé€²åº¦æ¢\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG4kjtdgc2jh",
        "outputId": "5666dcca-8afa-4a07-fd52-ba4833e3ff7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/39_Training_Dataset/39_Training_Dataset/train_data\" # å­˜æ”¾ .txt çš„è³‡æ–™å¤¾\n",
        "INFO_PATH = \"/content/drive/MyDrive/39_Training_Dataset/39_Training_Dataset/train_info.csv\" # æ¨™ç±¤çš„ .csv æª”è·¯å¾‘"
      ],
      "metadata": {
        "id": "lnI0_51wc4TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# è³‡æ–™å‰è™•ç†"
      ],
      "metadata": {
        "id": "n03XN049c8LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å‰è™•ç†ï¼šåˆ‡å‰²æ¯ç­†è³‡æ–™çš„ 27 æ¬¡æ®æ‹ä¸¦æå–çµ±è¨ˆç‰¹å¾µ\n",
        "from scipy.stats import kurtosis, skew\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def segment_swing(data, cut_points):\n",
        "    return [data[cut_points[i]:cut_points[i+1]] for i in range(27)]\n",
        "\n",
        "def extract_features(segment):\n",
        "    feats = []\n",
        "\n",
        "    acc = segment[:, 0:3]  # Ax, Ay, Az\n",
        "    gyro = segment[:, 3:6] # Gx, Gy, Gz\n",
        "\n",
        "    # ä¸‰è»¸å¹³å‡å€¼ï¼ˆå…±6ï¼‰\n",
        "    feats += list(acc.mean(axis=0))  # ax_mean, ay_mean, az_mean\n",
        "    feats += list(gyro.mean(axis=0))  # gx_mean, gy_mean, gz_mean\n",
        "\n",
        "    # ä¸‰è»¸è®Šç•°æ•¸ï¼ˆå…±6ï¼‰\n",
        "    feats += list(acc.var(axis=0))  # ax_var, ...\n",
        "    feats += list(gyro.var(axis=0))\n",
        "\n",
        "    # ä¸‰è»¸ RMSï¼ˆå¹³æ–¹æ ¹å¹³å‡ï¼‰ï¼ˆå…±6ï¼‰\n",
        "    feats += list(np.sqrt((acc ** 2).mean(axis=0)))\n",
        "    feats += list(np.sqrt((gyro ** 2).mean(axis=0)))\n",
        "\n",
        "    # åŠ é€Ÿåº¦ç¸½é‡ & è§’é€Ÿåº¦ç¸½é‡ï¼ˆä¸è€ƒæ…®æ–¹å‘ï¼‰\n",
        "    acc_total = np.linalg.norm(acc, axis=1)\n",
        "    gyro_total = np.linalg.norm(gyro, axis=1)\n",
        "\n",
        "    feats += [acc_total.max(), acc_total.min(), acc_total.mean()]  # 3\n",
        "    feats += [gyro_total.max(), gyro_total.min(), gyro_total.mean()]  # 3\n",
        "\n",
        "    # skewness + kurtosis + spectral entropyï¼ˆå„è»¸åŠ ç¸½ï¼Œå…± 6ï¼‰\n",
        "    for i in range(3):\n",
        "        a = acc[:, i]\n",
        "        g = gyro[:, i]\n",
        "\n",
        "        # Skewness & Kurtosis\n",
        "        feats += [skew(a), kurtosis(a)]\n",
        "        feats += [skew(g), kurtosis(g)]\n",
        "\n",
        "        # Spectral entropy (ç”¨ Welch é »è­œä¼°è¨ˆ)\n",
        "        for signal in [a, g]:\n",
        "            f, Pxx = welch(signal, nperseg=min(len(signal), 64))\n",
        "            Pxx /= Pxx.sum() + 1e-8\n",
        "            feats += [entropy(Pxx)]\n",
        "\n",
        "    return feats\n",
        "\n",
        "def preprocess_dataset(info_csv_path, data_dir, is_train=True):\n",
        "    df_info = pd.read_csv(info_csv_path)\n",
        "    feature_list = []\n",
        "    meta_list = []\n",
        "\n",
        "    for idx, row in df_info.iterrows():\n",
        "        uid = row[\"unique_id\"]\n",
        "        txt_path = os.path.join(data_dir, f\"{uid}.txt\")\n",
        "        if not os.path.exists(txt_path):\n",
        "            continue\n",
        "        try:\n",
        "            data = np.loadtxt(txt_path)\n",
        "            cut_str = row[\"cut_point\"]\n",
        "            cut_points = list(map(int, cut_str.strip(\"[]\").split()))\n",
        "            if len(cut_points) != 28:\n",
        "                continue  # è¦åˆ‡å‡º27æ®µï¼Œéœ€28å€‹é»\n",
        "            swings = segment_swing(data, cut_points)\n",
        "            # åŸæœ‰çš„ç‰¹å¾µæ“·å–\n",
        "            all_feats = [extract_features(s) for s in swings]\n",
        "            flatten_feats = np.concatenate(all_feats)  # shape: (1134,)\n",
        "\n",
        "            # ğŸ” æ–°å¢ mode ç‰¹å¾µï¼ˆ10 ç¶­ one-hotï¼‰\n",
        "            mode_idx = int(row[\"mode\"]) - 1  # å¾ 1~10 â†’ 0~9\n",
        "            mode_onehot = np.zeros(10)\n",
        "            if 0 <= mode_idx < 10:\n",
        "                mode_onehot[mode_idx] = 1\n",
        "\n",
        "            # â• åˆä½µé€²æ•´é«”ç‰¹å¾µ\n",
        "            full_feat = np.concatenate([flatten_feats, mode_onehot])  # shape: (1144,)\n",
        "\n",
        "            # â• åŠ å…¥æ¸…å–®\n",
        "            feature_list.append(full_feat)\n",
        "\n",
        "            if is_train:\n",
        "                meta_list.append({\n",
        "                    \"unique_id\": uid,\n",
        "                    \"gender\": 1 if row[\"gender\"] == 2 else 0,\n",
        "                    \"hold racket handed\": 1 if row[\"hold racket handed\"] == 2 else 0,\n",
        "                    \"play years\": row[\"play years\"],\n",
        "                    \"level\": row[\"level\"] - 2  # è½‰æˆ 0~3\n",
        "                })\n",
        "            else:\n",
        "                meta_list.append({\"unique_id\": uid})\n",
        "        except:\n",
        "            continue  # å¿½ç•¥æ ¼å¼éŒ¯èª¤æˆ–ç¼ºå¤±\n",
        "\n",
        "    df_feat = pd.DataFrame(feature_list, columns=[f\"f{i}\" for i in range(len(feature_list[0]))])\n",
        "    df_meta = pd.DataFrame(meta_list)\n",
        "    df_result = pd.concat([df_meta, df_feat], axis=1)\n",
        "    return df_result\n",
        "\n",
        "# â¬ åŸ·è¡Œå‰è™•ç†\n",
        "train_df = preprocess_dataset(INFO_PATH, DATA_DIR, is_train=True)\n",
        "test_df = preprocess_dataset(\"/content/drive/MyDrive/39_Test_Dataset/39_Test_Dataset/test_info.csv\",\"/content/drive/MyDrive/39_Test_Dataset/39_Test_Dataset/test_data\", is_train=False)\n",
        "\n",
        "train_df.to_csv(\"train_features.csv\", index=False)\n",
        "test_df.to_csv(\"test_features.csv\", index=False)\n",
        "print(\"âœ… train_features.csvå’Œtest_features.csv å·²å®Œæˆå‰è™•ç†\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omdwW2Wpc60G",
        "outputId": "8a2b2e9e-324b-4cfe-9991-aed8eb298bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-13e9f72d5776>:41: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  feats += [skew(g), kurtosis(g)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… train_features.csvå’Œtest_features.csv å·²å®Œæˆå‰è™•ç†\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ‰‹éƒ¨æ¨¡å‹\n",
        "# å„²å­˜å’Œé©—è­‰æ‰‹æ¨¡å‹"
      ],
      "metadata": {
        "id": "WxE5fGdDdBv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuRHMbvKcrSQ",
        "outputId": "5840b52b-f8a9-400f-e91a-a6d7b79aab0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: val_acc = 0.9309\n",
            "Epoch 2: val_acc = 0.9770\n",
            "Epoch 3: val_acc = 0.9847\n",
            "Epoch 4: val_acc = 0.9923\n",
            "Epoch 5: val_acc = 0.9949\n",
            "Epoch 6: val_acc = 0.9974\n",
            "Epoch 7: val_acc = 0.9974\n",
            "Epoch 8: val_acc = 1.0000\n",
            "Epoch 9: val_acc = 0.9974\n",
            "Epoch 10: val_acc = 1.0000\n",
            "Epoch 11: val_acc = 0.9974\n",
            "Epoch 12: val_acc = 1.0000\n",
            "Epoch 13: val_acc = 1.0000\n",
            "Epoch 14: val_acc = 1.0000\n",
            "Epoch 15: val_acc = 1.0000\n",
            "Epoch 16: val_acc = 1.0000\n",
            "Epoch 17: val_acc = 1.0000\n",
            "Epoch 18: val_acc = 1.0000\n",
            "Epoch 19: val_acc = 1.0000\n",
            "Epoch 20: val_acc = 1.0000\n"
          ]
        }
      ],
      "source": [
        "# é‡æ–°è¼‰å…¥æ–°çš„è¨“ç·´è³‡æ–™é›†ä¸¦è¨­å®šç‰¹å¾µæ¬„ä½\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "# è¼‰å…¥æ–°çš„ train_features\n",
        "df = pd.read_csv(\"train_features.csv\")\n",
        "\n",
        "# ç‰¹å¾µèˆ‡æ¨™ç±¤æ¬„ä½è¨­å®š\n",
        "X_full = df.drop(columns=[\"unique_id\", \"gender\", \"hold racket handed\", \"play years\", \"level\"])\n",
        "y_hand = df[\"hold racket handed\"].values\n",
        "\n",
        "# æå– Ax mean å’Œ Ax varï¼ˆæ¯æ®µæ®æ‹ï¼‰+ mode one-hotï¼ˆæœ€å¾Œ10æ¬„ï¼‰\n",
        "\"\"\"\n",
        "ax_indices = []\n",
        "for i in range(27):\n",
        "    base = i * 42\n",
        "    ax_indices += [base + 0, base + 6]  # Ax mean, Ax var\n",
        "mode_indices = list(range(X_full.shape[1] - 10, X_full.shape[1]))\n",
        "X_raw = X_full\n",
        "X_selected = X_raw.iloc[:, ax_indices + mode_indices].values\n",
        "\"\"\"\n",
        "# ç‰¹å¾µé¸å–èˆ‡æ¨™æº–åŒ–\n",
        "# ç¢ºèªæœ€å¾Œ10æ¬„æ˜¯ mode one-hotï¼Œä¸æ¨™æº–åŒ–\n",
        "mode_indices = list(range(X_full.shape[1] - 10, X_full.shape[1]))\n",
        "X_num = X_full.iloc[:, :-10].values\n",
        "X_mode = X_full.iloc[:, -10:].values\n",
        "\n",
        "# å°æ•¸å€¼ç‰¹å¾µæ¨™æº–åŒ–\n",
        "scaler = StandardScaler()\n",
        "X_num_scaled = scaler.fit_transform(X_num)\n",
        "# å„²å­˜ scaler\n",
        "joblib.dump(scaler, \"scaler_main.pkl\")\n",
        "\n",
        "# åˆä½µç‚ºæœ€çµ‚ç‰¹å¾µ\n",
        "X_scaled = np.concatenate([X_num_scaled, X_mode], axis=1)\n",
        "\n",
        "# åˆ‡åˆ†è¨“ç·´èˆ‡é©—è­‰\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_hand, test_size=0.2, stratify=y_hand, random_state=42)\n",
        "\n",
        "# å»ºç«‹ Dataset\n",
        "class HandDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(HandDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(HandDataset(X_val, y_val), batch_size=64)\n",
        "\n",
        "# å®šç¾©æ¨¡å‹\n",
        "class Binary_Hand_Classifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(-1)\n",
        "\n",
        "# è¨“ç·´æ¨¡å‹ï¼ˆä½¿ç”¨ GPUï¼Œå¦‚å¯ç”¨ï¼‰\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Binary_Hand_Classifier(X_scaled.shape[1]).to(device)\n",
        "weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "pos_weight = torch.tensor([weights[1]], dtype=torch.float32).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# å„²å­˜ scaler\n",
        "joblib.dump(scaler, \"scaler_main.pkl\")\n",
        "\n",
        "# è¨“ç·´éç¨‹\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # é©—è­‰ acc\n",
        "    model.eval()\n",
        "    all_preds, all_trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            out = torch.sigmoid(model(xb))\n",
        "            preds = (out > 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_trues.extend(yb.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_trues, all_preds)\n",
        "    print(f\"Epoch {epoch+1}: val_acc = {acc:.4f}\")\n",
        "\n",
        "# å„²å­˜æ¨¡å‹\n",
        "torch.save(model.state_dict(), \"hand_model.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# çƒé½¡å’Œç­‰ç´š"
      ],
      "metadata": {
        "id": "X9kcjboAAZZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# è®€å–ä½¿ç”¨è€…å‰›ä¸Šå‚³çš„è³‡æ–™\n",
        "df = pd.read_csv(\"train_features.csv\")\n",
        "\n",
        "# æª¢æŸ¥ level æ¬„ä½çš„å”¯ä¸€å€¼èˆ‡æ¯å€‹å€¼çš„å‡ºç¾æ¬¡æ•¸\n",
        "level_counts = df[\"level\"].value_counts().sort_index()\n",
        "level_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "UXBneEuzCxqw",
        "outputId": "62de26df-fdd0-4d68-a88a-c227bdebb166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "level\n",
              "0    715\n",
              "1    201\n",
              "2    136\n",
              "3    903\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>level</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è®€å–è³‡æ–™\n",
        "df = pd.read_csv(\"train_features.csv\")\n",
        "\n",
        "# åˆ‡åˆ†ç‰¹å¾µèˆ‡æ¨™ç±¤\n",
        "X_full = df.drop(columns=[\"unique_id\", \"gender\", \"hold racket handed\", \"play years\", \"level\"])\n",
        "y_years = df[\"play years\"].values\n",
        "y_level = df[\"level\"].values\n",
        "\n",
        "# ç¢ºèªæœ€å¾Œ10æ¬„æ˜¯ mode one-hotï¼Œä¸æ¨™æº–åŒ–\n",
        "mode_indices = list(range(X_full.shape[1] - 10, X_full.shape[1]))\n",
        "X_num = X_full.iloc[:, :-10].values\n",
        "X_mode = X_full.iloc[:, -10:].values\n",
        "\n",
        "# å°æ•¸å€¼ç‰¹å¾µæ¨™æº–åŒ–\n",
        "scaler = joblib.load(\"scaler_main.pkl\")\n",
        "X_num_scaled = scaler.fit_transform(X_num)\n",
        "\n",
        "# åˆä½µç‚ºæœ€çµ‚ç‰¹å¾µ\n",
        "X_all = np.concatenate([X_num_scaled, X_mode], axis=1)\n",
        "\n",
        "# æœ€å¾Œåˆ‡åˆ†è¨“ç·´/é©—è­‰é›†\n",
        "X_train_y, X_val_y, y_train_y, y_val_y = train_test_split(X_all, y_years, test_size=0.2, stratify=y_years, random_state=42)\n",
        "X_train_l, X_val_l, y_train_l, y_val_l = train_test_split(X_all, y_level, test_size=0.2, stratify=y_level, random_state=42)\n",
        "\n",
        "# Dataset é¡åˆ¥\n",
        "class MultiClassDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader_years = DataLoader(MultiClassDataset(X_train_y, y_train_y), batch_size=64, shuffle=True)\n",
        "val_loader_years = DataLoader(MultiClassDataset(X_val_y, y_val_y), batch_size=64)\n",
        "\n",
        "train_loader_level = DataLoader(MultiClassDataset(X_train_l, y_train_l), batch_size=64, shuffle=True)\n",
        "val_loader_level = DataLoader(MultiClassDataset(X_val_l, y_val_l), batch_size=64)\n",
        "\n",
        "# æ¨¡å‹\n",
        "class MultiClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# è¨“ç·´å‡½å¼\n",
        "def train_model(X_train, X_val, y_train, y_val, train_loader, val_loader, num_classes, model_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = MultiClassifier(X_train.shape[1], num_classes).to(device)\n",
        "    weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    for epoch in range(20):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # é©—è­‰\n",
        "        model.eval()\n",
        "        all_preds, all_trues = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                out = model(xb)\n",
        "                preds = torch.argmax(out, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_trues.extend(yb.cpu().numpy())\n",
        "        acc = accuracy_score(all_trues, all_preds)\n",
        "        print(f\"{model_name} Epoch {epoch+1}: val_acc = {acc:.4f}\")\n",
        "\n",
        "    # å„²å­˜æ¨¡å‹\n",
        "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
        "    return model\n",
        "\n",
        "# è¨“ç·´å…©å€‹æ¨¡å‹\n",
        "model_years = train_model(X_train_y, X_val_y, y_train_y, y_val_y, train_loader_years, val_loader_years, 3, \"play_years_model\")\n",
        "model_level = train_model(X_train_l, X_val_l, y_train_l, y_val_l, train_loader_level, val_loader_level, 4, \"level_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ7INIrmAZI1",
        "outputId": "892ed453-806d-4cf6-cbda-15a907dd9078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play_years_model Epoch 1: val_acc = 0.5754\n",
            "play_years_model Epoch 2: val_acc = 0.6240\n",
            "play_years_model Epoch 3: val_acc = 0.6343\n",
            "play_years_model Epoch 4: val_acc = 0.6650\n",
            "play_years_model Epoch 5: val_acc = 0.6777\n",
            "play_years_model Epoch 6: val_acc = 0.6880\n",
            "play_years_model Epoch 7: val_acc = 0.6982\n",
            "play_years_model Epoch 8: val_acc = 0.7084\n",
            "play_years_model Epoch 9: val_acc = 0.7289\n",
            "play_years_model Epoch 10: val_acc = 0.7442\n",
            "play_years_model Epoch 11: val_acc = 0.7570\n",
            "play_years_model Epoch 12: val_acc = 0.7749\n",
            "play_years_model Epoch 13: val_acc = 0.7954\n",
            "play_years_model Epoch 14: val_acc = 0.7980\n",
            "play_years_model Epoch 15: val_acc = 0.8082\n",
            "play_years_model Epoch 16: val_acc = 0.8133\n",
            "play_years_model Epoch 17: val_acc = 0.8184\n",
            "play_years_model Epoch 18: val_acc = 0.8389\n",
            "play_years_model Epoch 19: val_acc = 0.8491\n",
            "play_years_model Epoch 20: val_acc = 0.8542\n",
            "level_model Epoch 1: val_acc = 0.3836\n",
            "level_model Epoch 2: val_acc = 0.6113\n",
            "level_model Epoch 3: val_acc = 0.6010\n",
            "level_model Epoch 4: val_acc = 0.6394\n",
            "level_model Epoch 5: val_acc = 0.6496\n",
            "level_model Epoch 6: val_acc = 0.6931\n",
            "level_model Epoch 7: val_acc = 0.7110\n",
            "level_model Epoch 8: val_acc = 0.7340\n",
            "level_model Epoch 9: val_acc = 0.7263\n",
            "level_model Epoch 10: val_acc = 0.7519\n",
            "level_model Epoch 11: val_acc = 0.7749\n",
            "level_model Epoch 12: val_acc = 0.8031\n",
            "level_model Epoch 13: val_acc = 0.8210\n",
            "level_model Epoch 14: val_acc = 0.8363\n",
            "level_model Epoch 15: val_acc = 0.8593\n",
            "level_model Epoch 16: val_acc = 0.8568\n",
            "level_model Epoch 17: val_acc = 0.8772\n",
            "level_model Epoch 18: val_acc = 0.8747\n",
            "level_model Epoch 19: val_acc = 0.8824\n",
            "level_model Epoch 20: val_acc = 0.8824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ€§åˆ¥\n"
      ],
      "metadata": {
        "id": "j75WuusWG-x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# æº–å‚™è³‡æ–™\n",
        "df = pd.read_csv(\"train_features.csv\")\n",
        "X_full = df.drop(columns=[\"unique_id\", \"gender\", \"hold racket handed\", \"play years\", \"level\"])\n",
        "y_gender = df[\"gender\"].values\n",
        "\n",
        "# ç‰¹å¾µæ¨™æº–åŒ–ï¼ˆä¸å«æœ€å¾Œ10æ¬„ modeï¼‰\n",
        "X_num = X_full.iloc[:, :-10].values\n",
        "X_mode = X_full.iloc[:, -10:].values\n",
        "scaler = joblib.load(\"scaler_main.pkl\")\n",
        "X_num_scaled = scaler.fit_transform(X_num)\n",
        "X_combined = np.concatenate([X_num_scaled, X_mode], axis=1)\n",
        "\n",
        "# è³‡æ–™åˆ‡åˆ†\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_combined, y_gender, test_size=0.2, stratify=y_gender, random_state=42)\n",
        "\n",
        "# æ¬Šé‡è™•ç†ï¼ˆè™•ç†ä¸å¹³è¡¡ï¼‰\n",
        "weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "pos_weight = torch.tensor([weights[1]], dtype=torch.float32).to(device)\n",
        "\n",
        "# Dataset\n",
        "class GenderDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(GenderDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(GenderDataset(X_val, y_val), batch_size=64)\n",
        "\n",
        "# æ¨¡å‹æ¶æ§‹\n",
        "class Binary_Gender_Classifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(-1)\n",
        "\n",
        "# è¨“ç·´è¨­å®š\n",
        "model = Binary_Gender_Classifier(X_train.shape[1]).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# è¨“ç·´è¿´åœˆ\n",
        "train_accs, val_accs = [], []\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # é©—è­‰\n",
        "    model.eval()\n",
        "    preds, truths = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            out = torch.sigmoid(model(xb)).cpu()\n",
        "            preds.extend((out > 0.5).int().numpy())\n",
        "            truths.extend(yb.numpy())\n",
        "    acc = accuracy_score(truths, preds)\n",
        "    val_accs.append(acc)\n",
        "    print(f\"Epoch {epoch+1}: val_acc = {acc:.4f}\")\n",
        "\n",
        "# âœ… å„²å­˜æ¨¡å‹\n",
        "torch.save(model.state_dict(), \"gender_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAKn4Ve8HFsT",
        "outputId": "67234244-9049-4a00-ee07-9a3c4d6f97a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: val_acc = 0.9156\n",
            "Epoch 2: val_acc = 0.9412\n",
            "Epoch 3: val_acc = 0.9591\n",
            "Epoch 4: val_acc = 0.9693\n",
            "Epoch 5: val_acc = 0.9744\n",
            "Epoch 6: val_acc = 0.9719\n",
            "Epoch 7: val_acc = 0.9744\n",
            "Epoch 8: val_acc = 0.9795\n",
            "Epoch 9: val_acc = 0.9693\n",
            "Epoch 10: val_acc = 0.9770\n",
            "Epoch 11: val_acc = 0.9795\n",
            "Epoch 12: val_acc = 0.9744\n",
            "Epoch 13: val_acc = 0.9795\n",
            "Epoch 14: val_acc = 0.9821\n",
            "Epoch 15: val_acc = 0.9744\n",
            "Epoch 16: val_acc = 0.9770\n",
            "Epoch 17: val_acc = 0.9821\n",
            "Epoch 18: val_acc = 0.9847\n",
            "Epoch 19: val_acc = 0.9795\n",
            "Epoch 20: val_acc = 0.9795\n",
            "Epoch 21: val_acc = 0.9795\n",
            "Epoch 22: val_acc = 0.9693\n",
            "Epoch 23: val_acc = 0.9795\n",
            "Epoch 24: val_acc = 0.9770\n",
            "Epoch 25: val_acc = 0.9795\n",
            "Epoch 26: val_acc = 0.9770\n",
            "Epoch 27: val_acc = 0.9719\n",
            "Epoch 28: val_acc = 0.9693\n",
            "Epoch 29: val_acc = 0.9770\n",
            "Epoch 30: val_acc = 0.9821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ç”Ÿæˆsubmission"
      ],
      "metadata": {
        "id": "nhoHyyjnNBGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== é‡æ–°è¼‰å…¥æª”æ¡ˆ ======\n",
        "test_path = \"test_features.csv\"\n",
        "df_test = pd.read_csv(test_path)\n",
        "X_test_raw = df_test.drop(columns=[\"unique_id\"])\n",
        "unique_ids = df_test[\"unique_id\"].tolist()\n",
        "\n",
        "# æ¨¡å‹æ¬„ä½è™•ç†\n",
        "num_features = X_test_raw.shape[1] - 10\n",
        "X_main = X_test_raw.iloc[:, :num_features].values\n",
        "X_mode = X_test_raw.iloc[:, num_features:].values\n",
        "\n",
        "# æ¨™æº–åŒ–ä¸»ç‰¹å¾µæ¬„ä½\n",
        "scaler = joblib.load(\"scaler_main.pkl\")\n",
        "X_main_scaled = scaler.fit_transform(X_main)\n",
        "X_test_scaled = np.hstack([X_main_scaled, X_mode])\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "\n",
        "# ====== è¼‰å…¥æ¨¡å‹ä¸¦æ¨è«– ======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_hand = Binary_Hand_Classifier(X_test_scaled.shape[1]).to(device)\n",
        "model_gender = Binary_Gender_Classifier(X_test_scaled.shape[1]).to(device)\n",
        "model_years = MultiClassifier(X_test_scaled.shape[1], 3).to(device)\n",
        "model_level = MultiClassifier(X_test_scaled.shape[1], 4).to(device)\n",
        "\n",
        "model_hand.load_state_dict(torch.load(\"hand_model.pth\", map_location=device))\n",
        "model_gender.load_state_dict(torch.load(\"gender_model.pth\", map_location=device))\n",
        "model_years.load_state_dict(torch.load(\"play_years_model.pth\", map_location=device))\n",
        "model_level.load_state_dict(torch.load(\"level_model.pth\", map_location=device))\n",
        "\n",
        "model_hand.eval()\n",
        "model_gender.eval()\n",
        "model_years.eval()\n",
        "model_level.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_hand = torch.sigmoid(model_hand(X_test_tensor.to(device))).cpu().numpy()\n",
        "    pred_gender = torch.sigmoid(model_gender(X_test_tensor.to(device))).cpu().numpy()\n",
        "    pred_years = torch.softmax(model_years(X_test_tensor.to(device)), dim=1).cpu().numpy()\n",
        "    pred_level = torch.softmax(model_level(X_test_tensor.to(device)), dim=1).cpu().numpy()\n",
        "\n",
        "\n",
        "# å° pred_years å’Œ pred_level é€²è¡Œ row-wise æ­£è¦åŒ–ï¼ˆsoftmax æˆ–ç°¡å–®æ¯”ä¾‹ï¼‰\n",
        "pred_years = pred_years / pred_years.sum(axis=1, keepdims=True)\n",
        "pred_level = pred_level / pred_level.sum(axis=1, keepdims=True)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"unique_id\": unique_ids,\n",
        "    \"gender\": pred_gender,  # ä¿ç•™åŸå§‹æ©Ÿç‡\n",
        "    \"hold racket handed\": pred_hand,\n",
        "    \"play years_0\": pred_years[:, 0],\n",
        "    \"play years_1\": pred_years[:, 1],\n",
        "    \"play years_2\": pred_years[:, 2],\n",
        "    \"level_2\": pred_level[:, 0],\n",
        "    \"level_3\": pred_level[:, 1],\n",
        "    \"level_4\": pred_level[:, 2],\n",
        "    \"level_5\": pred_level[:, 3],\n",
        "})\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "import numpy as np\n",
        "\n",
        "# å…ˆè£œ NaNï¼Œå†æ ¼å¼åŒ–\n",
        "submission.fillna(submission.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "def format_float(val):\n",
        "    if pd.isna(val):\n",
        "        return val  # ä¿ç•™ NaNï¼ˆä½†å…¶å¯¦é€™é‚Šå·²è£œå®Œï¼‰\n",
        "    return \"{:.4f}\".format(Decimal(val).quantize(Decimal('0.0001'), rounding=ROUND_HALF_UP))\n",
        "\n",
        "# æ ¼å¼åŒ–å°æ•¸ï¼ˆä¸å« unique_idï¼‰\n",
        "for col in submission.columns[1:]:\n",
        "    submission[col] = submission[col].apply(format_float)\n",
        "\n",
        "# å„²å­˜ CSVï¼Œé¿å…å¯«å‡ºç§‘å­¸è¨˜è™Ÿ\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "rh7teGA6NAgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}